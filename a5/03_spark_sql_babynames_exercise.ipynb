{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8rtKd-TDaxs"
      },
      "source": [
        "#### Name: `Jike Lu`\n",
        "#### AndrewID: `jikelu`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-tK1XA08Daxu"
      },
      "source": [
        "## Determining the most popular gender neutral names"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6y0hhD5vDaxu"
      },
      "source": [
        "The United States Social Security administration keeps records of all births and provides some of this [data](https://www.ssa.gov/oact/babynames) to the public in a file where each line is of the format:\n",
        "\n",
        "KY,F,1912,Dorothy,209\n",
        "\n",
        "this is to be interpreted as \"In 1912, 209 female babies were born in Kentucky who were given the first name Dorothy\".\n",
        "\n",
        "In this exercise you are to write a pyspark program that works with RDDs to determine the most popular gender neutral names.  We define a gender neutral name as a baby name that has been given to both a boy and girl baby.  We define a popular gender neutral name as a name where the ratio of the number of boys with that name to the number of girls with that name is in the range \\[0.25..4\\]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNcKTVAIDaxu"
      },
      "source": [
        "The whole babynames file from the SSA has 6028151 records (lines) and information on ??? babies.   To facilitate development, I've sampled 100,000 lines in the file `babynames-100k.csv`.  During development, working with the sample.  Once done, set `test` to `False` run your code and submit your notebook"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://downloads.apache.org/dist/spark/spark-3.3.2/spark-3.3.2-bin-hadoop3.tgz\n",
        "!tar xf spark-3.3.2-bin-hadoop3.tgz\n",
        "!pip install -q findspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zLhFzNEZDuNp",
        "outputId": "235ed278-3a51-46d0-df01-77dd353c8a60"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tar: spark-3.3.2-bin-hadoop3.tgz: Cannot open: No such file or directory\n",
            "tar: Error is not recoverable: exiting now\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "mtXxYtkXDaxv"
      },
      "outputs": [],
      "source": [
        "test = False\n",
        "if test:\n",
        "    file_name = 'babynames-100k.csv'\n",
        "else:\n",
        "    file_name = 'babynames2018_state_gender_year_fname_number.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "O8sUKSMjDaxw"
      },
      "outputs": [],
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark import SparkContext\n",
        "sc = SparkContext()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "O-Z9OHF2Daxw"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.getOrCreate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54h1OeY6Daxw"
      },
      "source": [
        "## Babies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-BV-YquDaxx",
        "outputId": "977563a7-a889-4cf6-870f-16d20c9fe2ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AK,F,1910,Mary,14\r\n",
            "AK,F,1910,Annie,12\r\n",
            "AK,F,1910,Anna,10\r\n",
            "AK,F,1910,Margaret,8\r\n",
            "AK,F,1910,Helen,7\r\n",
            "AK,F,1910,Elsie,6\r\n",
            "AK,F,1910,Lucy,6\r\n",
            "AK,F,1910,Dorothy,5\r\n",
            "AK,F,1911,Mary,12\r\n",
            "AK,F,1911,Margaret,7\r\n"
          ]
        }
      ],
      "source": [
        "!head babynames2018_state_gender_year_fname_number.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "OtYZ5_PYDaxx"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.types import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "h-vOY-IBDaxx"
      },
      "outputs": [],
      "source": [
        "schema = StructType([\n",
        "    StructField('state', StringType(), False),\n",
        "    StructField('gender', StringType(), False),\n",
        "    StructField('year', IntegerType(), False),\n",
        "    StructField('name', StringType(), False),\n",
        "    StructField('number', IntegerType(), False)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "HCPOpHhYDaxx"
      },
      "outputs": [],
      "source": [
        "baby_names = spark.read.csv(file_name, schema=schema)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "id": "z_0thv2kDaxx",
        "outputId": "c33e9644-3618-4fdb-d9a1-7de55ba9c26e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyspark.sql.dataframe.DataFrame"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>pyspark.sql.dataframe.DataFrame</b><br/>def __init__(jdf: JavaObject, sql_ctx: Union[&#x27;SQLContext&#x27;, &#x27;SparkSession&#x27;])</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/pyspark/sql/dataframe.py</a>A distributed collection of data grouped into named columns.\n",
              "\n",
              ".. versionadded:: 1.3.0\n",
              "\n",
              ".. versionchanged:: 3.4.0\n",
              "    Supports Spark Connect.\n",
              "\n",
              "Examples\n",
              "--------\n",
              "A :class:`DataFrame` is equivalent to a relational table in Spark SQL,\n",
              "and can be created using various functions in :class:`SparkSession`:\n",
              "\n",
              "&gt;&gt;&gt; people = spark.createDataFrame([\n",
              "...     {&quot;deptId&quot;: 1, &quot;age&quot;: 40, &quot;name&quot;: &quot;Hyukjin Kwon&quot;, &quot;gender&quot;: &quot;M&quot;, &quot;salary&quot;: 50},\n",
              "...     {&quot;deptId&quot;: 1, &quot;age&quot;: 50, &quot;name&quot;: &quot;Takuya Ueshin&quot;, &quot;gender&quot;: &quot;M&quot;, &quot;salary&quot;: 100},\n",
              "...     {&quot;deptId&quot;: 2, &quot;age&quot;: 60, &quot;name&quot;: &quot;Xinrong Meng&quot;, &quot;gender&quot;: &quot;F&quot;, &quot;salary&quot;: 150},\n",
              "...     {&quot;deptId&quot;: 3, &quot;age&quot;: 20, &quot;name&quot;: &quot;Haejoon Lee&quot;, &quot;gender&quot;: &quot;M&quot;, &quot;salary&quot;: 200}\n",
              "... ])\n",
              "\n",
              "Once created, it can be manipulated using the various domain-specific-language\n",
              "(DSL) functions defined in: :class:`DataFrame`, :class:`Column`.\n",
              "\n",
              "To select a column from the :class:`DataFrame`, use the apply method:\n",
              "\n",
              "&gt;&gt;&gt; age_col = people.age\n",
              "\n",
              "A more concrete example:\n",
              "\n",
              "&gt;&gt;&gt; # To create DataFrame using SparkSession\n",
              "... department = spark.createDataFrame([\n",
              "...     {&quot;id&quot;: 1, &quot;name&quot;: &quot;PySpark&quot;},\n",
              "...     {&quot;id&quot;: 2, &quot;name&quot;: &quot;ML&quot;},\n",
              "...     {&quot;id&quot;: 3, &quot;name&quot;: &quot;Spark SQL&quot;}\n",
              "... ])\n",
              "\n",
              "&gt;&gt;&gt; people.filter(people.age &gt; 30).join(\n",
              "...     department, people.deptId == department.id).groupBy(\n",
              "...     department.name, &quot;gender&quot;).agg({&quot;salary&quot;: &quot;avg&quot;, &quot;age&quot;: &quot;max&quot;}).show()\n",
              "+-------+------+-----------+--------+\n",
              "|   name|gender|avg(salary)|max(age)|\n",
              "+-------+------+-----------+--------+\n",
              "|     ML|     F|      150.0|      60|\n",
              "|PySpark|     M|       75.0|      50|\n",
              "+-------+------+-----------+--------+\n",
              "\n",
              "Notes\n",
              "-----\n",
              "A DataFrame should only be created as described above. It should not be directly\n",
              "created via using the constructor.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 80);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "type(baby_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "qNmvCfeiDaxx"
      },
      "outputs": [],
      "source": [
        "baby_names.createOrReplaceTempView(\"baby_names\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Io99wbaaDaxx",
        "outputId": "f6703491-3def-4bf0-e871-5d7d00eb0303"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+\n",
            "|      cnt|\n",
            "+---------+\n",
            "|311155210|\n",
            "+---------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark.sql('''\n",
        "SELECT sum(number) as cnt\n",
        "  FROM baby_names\n",
        "''').show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "A67Tx4BPDaxx"
      },
      "outputs": [],
      "source": [
        "male_names = spark.sql('''\n",
        "SELECT name, SUM(number) AS male_count\n",
        "FROM baby_names\n",
        "WHERE gender = 'M'\n",
        "GROUP BY name\n",
        "''')\n",
        "\n",
        "female_names = spark.sql('''\n",
        "SELECT name, SUM(number) AS female_count\n",
        "FROM baby_names\n",
        "WHERE gender = 'F'\n",
        "GROUP BY name\n",
        "''')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oflmGKR9Daxy",
        "outputId": "e24f913f-81c7-42ac-d033-dde48396857e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(13785, 20852)"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "male_names.count(), female_names.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Tk4WcejrDaxy"
      },
      "outputs": [],
      "source": [
        "male_names.createOrReplaceTempView(\"male_names\")\n",
        "female_names.createOrReplaceTempView(\"female_names\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Gls9s6D6Daxy"
      },
      "outputs": [],
      "source": [
        "both_names = spark.sql('''\n",
        "SELECT\n",
        "    m.name,\n",
        "    m.male_count,\n",
        "    f.female_count,\n",
        "    (m.male_count + f.female_count) AS total_count\n",
        "FROM male_names m\n",
        "JOIN female_names f\n",
        "ON m.name = f.name\n",
        "''')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_LMn7EaNDaxy",
        "outputId": "e7fda344-8b52-4951-9951-03f58b5503e3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3042"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "both_names.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Fowztj2eDaxy"
      },
      "outputs": [],
      "source": [
        "both_names.createOrReplaceTempView(\"both_names\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G29IzayTDaxy",
        "outputId": "0a48a25c-933c-469d-c10f-c72ae9a17550"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----------+------------+-----------+\n",
            "|   name|male_count|female_count|total_count|\n",
            "+-------+----------+------------+-----------+\n",
            "|  James|   4997327|       18257|    5015584|\n",
            "|   John|   4869607|       15677|    4885284|\n",
            "| Robert|   4734038|       15116|    4749154|\n",
            "|Michael|   4349307|       17217|    4366524|\n",
            "|William|   3890923|       10211|    3901134|\n",
            "|   Mary|      9642|     3741196|    3750838|\n",
            "|  David|   3597725|        8185|    3605910|\n",
            "|Richard|   2539873|        4994|    2544867|\n",
            "| Joseph|   2522812|        5625|    2528437|\n",
            "|Charles|   2273068|        7532|    2280600|\n",
            "+-------+----------+------------+-----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark.sql('''\n",
        "SELECT\n",
        "    name,\n",
        "    male_count,\n",
        "    female_count,\n",
        "    total_count\n",
        "FROM both_names\n",
        "ORDER BY total_count DESC\n",
        "LIMIT 10\n",
        "\n",
        "''').show()"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "hBzl0xnzDaxy"
      },
      "source": [
        "Answer:\n",
        "\n",
        "+------+------+------+------+------------------+\n",
        "|  name|  msum|  fsum|     s|                 r|\n",
        "+------+------+------+------+------------------+\n",
        "|Willie|412266|121147|533413|3.4030227739853236|\n",
        "|Jordan|371032|130045|501077|2.8531046945288169|\n",
        "|Taylor|105876|319630|425506|0.3312455026123956|\n",
        "|Leslie|103893|263926|367819|0.3936444306358601|\n",
        "| Jamie| 82429|265776|348205|0.3101446330744687|\n",
        "| Angel|229363| 93378|322741|2.4562852063655251|\n",
        "|   Lee|215694| 55614|271308|3.8784119106699752|\n",
        "|  Dana| 48707|188651|237358|0.2581857504068359|\n",
        "|Jessie| 99340|130474|229814|0.7613777457577755|\n",
        "|Marion| 63382|163432|226814|0.3878187870184542|\n",
        "+------+------+------+------+------------------+"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CGW2oQa4Daxy"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}